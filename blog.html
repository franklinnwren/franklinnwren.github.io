<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Xtra Blog</title>
	<link rel="stylesheet" href="fontawesome/css/all.min.css"> <!-- https://fontawesome.com/ -->
	<link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro&display=swap" rel="stylesheet"> <!-- https://fonts.google.com/ -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/templatemo-xtra-blog.css" rel="stylesheet">
<!--
    
TemplateMo 553 Xtra Blog

https://templatemo.com/tm-553-xtra-blog

-->
</head>
<body>
	<header class="tm-header" id="tm-header">
        <div class="tm-header-wrapper">
            <button class="navbar-toggler" type="button" aria-label="Toggle navigation">
                <i class="fas fa-bars"></i>
            </button>
            <div class="tm-site-header">
                <div class="mb-3 mx-auto tm-site-logo"><i class="fas fa-times fa-2x"></i></div>            
                <h1 class="text-center">Xtra Blog</h1>
            </div>
            <nav class="tm-nav" id="tm-nav">            
                <ul>
                    <li class="tm-nav-item"><a href="index.html" class="tm-nav-link">
                        <i class="fas fa-home"></i>
                        Blog Home
                    </a></li>
                    <li class="tm-nav-item active"><a href="post.html" class="tm-nav-link">
                        <i class="fas fa-pen"></i>
                        Single Post
                    </a></li>
                </ul>
            </nav>
        </div>
    </header>
    <div class="container-fluid">
        <main class="tm-main">          
            <div class="row tm-row">
                <div class="col-12">
                    <hr class="tm-hr-primary tm-mb-55">
                    <!-- Video player 1422x800 -->
                    <video width="954" height="535" controls class="tm-mb-40">
                        <source src="video/wheat-field.mp4" type="video/mp4">							  
                        Your browser does not support the video tag.
                    </video>
                </div>
            </div>
            <div class="row tm-row">
                <div class="col-lg-8 tm-post-col">
                    <div class="tm-post-full">                    
                        <div class="mb-4">
                            <h2 class="pt-2 tm-color-primary tm-post-title">ChatGPT, Geoffrey Hinton, Fundamental Structure, and Beyond</h2>
                            <p class="tm-mb-40">Mar 8, 2023 posted by Franklin Ren</p>
                            <p>
                                Since the release of ChatGPT in late 2022, discussions have once again been raised about whether AGI is achievable in our generation. Partly because the power of large language generative models has exceeded the expectation of many – whether inside the AI research community or not – and brought their imagination about what AI could do to another level. The last time when we see a phenomenon like this is the AlphaGo moment, where Go – considered to be one of the most challenging tasks for the human brain – was overcome by an amazing deep reinforcement learning algorithm, and allowed people to imagine that the level of intelligence of AI algorithm will surpass human in a few years. Now, of course, we already know the speculation at that time was over-optimistic. The generalizability of deep learning algorithms stays a huge problem for many years, and researchers have to train those not-so-cool downstream task models one by one, hoping that one of them could turn into profit for the industry. The release of ChatGPT during NeurIPS 2022 seems to bring back people’s optimism about AI to the world, whereas a large language model (LLM) seems to have the generalizability of many different NLP tasks, and fulfill them in an amazing way. Many big names, including Ilya Sustkever, claimed that artificial general intelligence (AGI) is already on the level of the horizon in our generation. 
                                <a rel="nofollow" href="https://templatemo.com/tm-553-xtra-blog" target="_blank">Xtra Blog Template</a> 
                            </p>
                            <p>
                                During this wave of enthusiasm and revelry, one man seems not to be happy, we have not heard any comments from him, whether publicly or not, about the recent progress of large language models. Neither have we heard about any kind of follow-up work he proposed to catch up on the paradigm shift from small, separate language tasks to more generalizable large language models. The only time we saw him was when he proposed a brand-new fundamental AI structure in a venerable venue, and urged people, using his 74-year-old yet very vibrant voice, to RETHINK THE FUNDAMENTAL STRUCTURE in the field of AI. If some other people question the power of the deep neural network, possibly people will think that he or she is mad. But when this man talked about it, everyone – at least those within the AI community – have to take it seriously.
                            </p>
                            <p>
                                This man is Geoffrey Hinton, appearing on the venue of NeurIPS again, 10 years after his amazing AlexNet algorithm opens the door for the deep learning we all know today. People talk about him and write stories about him, on how he and his group bring a widely-considered-to-be-dead AI framework to one of the most probable ways to achieve AGI. Now he sitting virtually at the conference, asking people to cool down, claiming that what he helped create is not – and never be – the ideal path to AGI. In his talk, Hinton reinstated his disbelief that people are learning in a back propagation way – the way we use for all deep learning algorithms. He also pointed out that all current computer programs, including deep learning algorithms, are written based on a way that they only do what humans ask them to do, in an accurate way, without self-exploration, with reconsideration. However, that is not how humans gain knowledge about the world. Furthermore, he claimed that an AGI, which could learn by itself and create new knowledge in its own way, has to be built on a totally new architecture where hardware and software are developed jointly in order to fulfill the unique need of an AI system. In other words, not only do we need to redesign machine learning algorithms, but we also need to redesign the CPU, GPU, and every possible fundamental structure for computing.
                            </p>
                            <p>
                                This is not the first time he makes comments like this. In fact, Hinton has long been unsatisfied with the lack of focus from academia on rethinking and redesigning the fundamental structure of AI systems. As early as 2017 (one year after AlphaGo, when everyone still enjoyed the excitement of AI), in a talk at Fields Institute of the University of Toronto, he claimed that “people should abandon the idea of back-propagation”. Later in the same year, his team published a paper “Dynamic Routing Between Capsules”, trying to create a new structure for neural networks (NN). In his view, that would be a few-year-long project. At the AAAI conference in 2020, he reiterated again that CNN and similar algorithms have “unsolvable fundamental limits”. This time he brought together Yann Lecun and Yoshua Bengio (basically the top three magnets in the deep learning community) to call for people’s attention. Finally, three days after the release of ChatGPT, with the proposal of a not-so-established forward-forward algorithm, he urged again the need of rethinking the fundamental structure of deep learning. The only question is, will people actually buy it?
                            </p>
                            <p>
                                Hardly so. After the release of ChatGPT, Google responded immediately by introducing its own LLM, BARD, and started dumping tremendous resources into it. They even introduced another large model called PaLM-E when I was writing the article, unifying visuals, language, and robotics together. Meta also responded by introducing an open-source LLM called LLaMA (they all sound crazily similar). The government of China has listed LLM as one of the national strategies in competition with America. Start-ups appear one by one, including Stability, Jasper, and Anthropic (which receives 1B investment, in this hard year!). Not to mention a bunch of researchers trying to publish their papers based on ChatGPT. A very funny moment is when people tried to learn a way to attack ChatGPT using a NN model, but another day when they woke up, they realized OpenAI has fixed the bug. How about Hinton’s talk in NeurIPS? It seems to be forgotten.
                            </p>
                            <p>
                                To be continue...
                            </p>
                            <span class="d-block text-right tm-color-primary">Creative . Design . Business</span>
                        </div>
                        
                        <!-- Comments -->
                        <div>
                            <h2 class="tm-color-primary tm-post-title">Comments</h2>
                            <hr class="tm-hr-primary tm-mb-45">
                            <form action="" class="mb-5 tm-comment-form">
                                <h2 class="tm-color-primary tm-post-title mb-4">Your comment</h2>
                                <div class="mb-4">
                                    <input class="form-control" name="name" type="text">
                                </div>
                                <div class="mb-4">
                                    <input class="form-control" name="email" type="text">
                                </div>
                                <div class="mb-4">
                                    <textarea class="form-control" name="message" rows="6"></textarea>
                                </div>
                                <div class="text-right">
                                    <button class="tm-btn tm-btn-primary tm-btn-small">Submit</button>                        
                                </div>                                
                            </form>                          
                        </div>
                    </div>
                </div>
            </div>
            <footer class="row tm-row">
                <div class="col-md-6 col-12 tm-color-gray">
                    Design: <a rel="nofollow" target="_parent" href="https://templatemo.com" class="tm-external-link">TemplateMo</a>
                </div>
                <div class="col-md-6 col-12 tm-color-gray tm-copyright">
                    Copyright 2020 Xtra Blog Company Co. Ltd.
                </div>
            </footer>
        </main>
    </div>
    <script src="js/jquery.min.js"></script>
    <script src="js/templatemo-script.js"></script>
</body>
</html>